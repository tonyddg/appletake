train_env:
  type: src.gym_env.plane_box.three:ThreeEnv
  kwargs:

    debug_close_pr: True

    env_pr: '@pr'
    subenv_mid_name : "#"
    subenv_range: [0, 4]

    obs_trans: "@ext_trans"
    obs_source: "depth"

    # env_init_box_pos_range: [
    #     [-25, -25, -10, -1, -1, -5],
    #     [25, 25, 10, 1, 1, 5]
    # ]
    # env_init_vis_pos_range: [
    #     [-8, -8, -2, -1, -1, -1],
    #     [8, 8, 2, 1, 1, 1]
    # ]
    # env_action_noise: [
    #   0.5, 0.5, 0.5, 0.1, 0.1, 0.1
    # ]
    # env_vis_persp_deg_disturb: 3
    # env_movbox_size_range: [
    #   [0.12, 0.12, 0.12],
    #   [0.30, 0.30, 0.20]
    # ]

    # env_movebox_center_err: [
    #     [-25, -25, -10, -1, -1, -5],
    #     [25, 25, 10, 1, 1, 5]
    # ]

    env_init_box_pos_range: [
        [-25, -25, -10, -3, -3, -5],
        [25, 25, 10, 3, 3, 5]
    ]
    env_init_vis_pos_range: [
        [-8, -8, -2, -1, -1, -1],
        [8, 8, 2, 1, 1, 1]
    ]
    env_action_noise: [
      0.5, 0.5, 0.5, 0.1, 0.1, 0.1
    ]
    env_vis_persp_deg_disturb: 3
    env_movbox_size_range: [
      [0.12, 0.12, 0.12],
      [0.30, 0.30, 0.20]
    ]

    env_movebox_center_err: [
        [-25, -25, -10, -1, -1, -5],
        [25, 25, 10, 1, 1, 5]
    ]

    env_is_unlimit_time: True
    # env_is_terminate_when_insert: True
    env_max_step: 20
    "@env_reward_fn": 
      type: "reward_passive_fn"
      kwargs:
        align_fail_panelty: -0.02 # -0.02 # -0.05 # -0.0
        timeout_panelty: ~

        max_align_pos_dis_mm: 8
        max_align_rot_dis_deg: 1.5

        max_approach_pos_dis_mm: 40
        max_approach_rot_dis_deg: 8 

        max_move_pos_dis_mm: 10
        max_move_rot_dis_deg: 4

        is_attract_to_center: true
        is_square_align_reward: true

        max_align_reward: 4
        max_approach_reward: 0.1 # 0 # 0.1
        max_move_reward: 0.1

    act_unit: [5, 5, 5, 1, 1, 1]
    act_type: "DESICION_PDDPG"

    env_tolerance_offset: 0.010 # 0.010
    env_center_adjust: 0.0025
    env_align_deg_check: 1.5
    env_random_sigma: ~

    three_fixbox_size_range:
      - [0.12, 0.12, 0.12]
      - [0.30, 0.30, 0.20]

    three_extra_fixbox_prob: 0.5
    three_size_disturb_range: [0.00, 0.030]
    three_box_gap_range: [0, 0.010]
    three_is_zero_middle: false

  wrapper: 
    -
      type: 'src.sb3.vec_wrap:NetFeatObsWrapper'
      kwargs:
        "@net": 
          type: "make_effv1_backbone"
          kwargs:
            path: "model/plane_box/ext/three/best.pth"
        feat_dim: 1280

eval_env:
  is_base_on_train: True
  type: src.gym_env.plane_box.three:ThreeEnv
  kwargs:
    env_pr: '@pr'
    subenv_mid_name: '#'
    subenv_range:
    - 4
    - 6

model:
  type: stable_baselines3:SAC
  kwargs:
    policy: MlpPolicy
    policy_kwargs:
      net_arch:
      - 512
      - 256
    batch_size: 256
    learning_rate: 0.00356
    buffer_size: 8192
    learning_starts: 1024
    train_freq: 1
    gradient_steps: 4
    gamma: 0.9
    tau: 0.001

trial:
  total_timesteps: 95000 # 1500000
  meta_manual_seed: 0
  meta_exp_root: runs/plane_box/finetuning/three_finetuning/ppo_ext
  meta_exp_name: trial
  eval_freq: 5000
  eval_num_episodes: 100
  eval_pruner_warmup_ratio: 0.4
  tb_record_episodes: 3
  tb_record_flag: ALL
  tb_record_last_only: true
  meta_object_path: runs/plane_box/finetuning/three_finetuning/ppo_ext

  tb_rollout_log_record_dict:
    critic_loss: "train/critic_loss"
    actor_loss: "train/actor_loss"
  # tb_log_critic_loss_name: train/value_loss
  # tb_log_actor_loss_name: train/loss
